<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="" />

<meta name="date" content="2021-09-14" />

<title>Week 3</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Environmental Science</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Syllabus
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data science
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Week 1</li>
    <li>
      <a href="Rintro.html">The R and RStudio environments</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Climate science
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Week 1</li>
    <li>
      <a href="AQintro.html">Air Quality Lab Introduction</a>
    </li>
    <li class="dropdown-header">Week 2</li>
    <li>
      <a href="AQexp1.html">Air Quality: Test transects</a>
    </li>
    <li class="dropdown-header">Week 3</li>
    <li>
      <a href="AQexp2.html">Air Quality: Analysis</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Week 3</h1>
<h4 class="date">2021-09-14</h4>

</div>


<div id="where-can-i-find-the-code" class="section level1">
<h1>Where can I find the code?</h1>
<p>Going forward, we may shift to using RStudio Cloud. The campus’ RStudio Server will eventually be migrated completely to RStudio Cloud, which offers several major advantages.</p>
<ul>
<li>You can find the <a href="https://rstudio.cloud/spaces/170230/project/2880162">project link here</a>.
<ul>
<li>Please sign up for RStudio Cloud using your Pomona credentials.</li>
<li>For Pomona students, this is your email address. You can use a different password though.</li>
<li>For non-Pomona students, this is your Pomona account (e.g. sage4747). You can also use a different password.</li>
</ul></li>
<li>Alternatively, you can read the instructions on this website and follow along running the R code using an <a href="https://github.com/EA30POM/Fall2021/blob/main/docs/Rscripts/Week3.R">Rscript from our class repository</a>; <a href="https://raw.githubusercontent.com/EA30POM/Fall2021/main/docs/Rscripts/Week3.R">raw version to copy-paste</a>.</li>
<li>Finally, if you’d like to learn about <a href="https://bookdown.org/yihui/rmarkdown/basics.html">RMarkdown</a>, you’re welcome to use the RMarkdown file at the RStudio Cloud site (should be in the folder <code>EA30F21</code>) or <a href="https://github.com/EA30POM/Fall2021/blob/main/docs/AQexp2.Rmd">from our class repository</a>. The <a href="https://raw.githubusercontent.com/EA30POM/Fall2021/main/docs/AQexp1.Rmd">raw version is here which can be easier to copy</a>.</li>
</ul>
</div>
<div id="how-do-we-know-when-our-data-indicate-something-meaningful-statistically" class="section level1">
<h1>How do we know when our data indicate something meaningful statistically?</h1>
<p>Let’s play pretend for a moment. In understanding how to analyze our air quality data, we can take advantage of a powerful tool from computing: <strong>simulating</strong> our data.</p>
<p>What we are going to do here is pretend:</p>
<ul>
<li>We live in a location with some specific AQI and some amount of variation in its AQI;</li>
<li>We took a certain number of samples measuring AQI;</li>
<li>We repeated these measurements for comparable environmental conditions.</li>
</ul>
<p>Below, let’s say we live somewhere where the mean AQI is 75 and the <a href="https://simple.wikipedia.org/wiki/Standard_deviation">standard deviation</a> (a.k.a. “sd”) is 25 AQI points. In this first example, we will also assume that the distribution of AQI values in Pretend City, USA is roughly <a href="https://simple.wikipedia.org/wiki/Normal_distribution">normal</a>. Standard deviation tells us how much the data are spread out from the mean value (higher sd –&gt; more spread; lower sd –&gt; less spread). A Normal distribution is the familiar “bell-shaped” curve.</p>
<p>We’re going to assume that we took 30 distinct measurements of air quality. What happens when we repeat our observations of air quality 9 times in Pretend City?</p>
<p>In the plots below, each of the sub-plots is one of the 9 repeated samples. Each sample has 30 measurements. And the AQI values that compose each sample come from a normal distribution with a mean AQI of 75 and an sd of 25. The blue line shows us the mean value of the AQI values in each sample.</p>
<pre class="r"><code>sim_AQI_data(true_mean=75, true_sd=25, n_obs=30, how_many=9) # trial 1</code></pre>
<p><img src="AQexp2_files/figure-html/simAQIv1-1.png" width="672" /></p>
<p>What do we observe in the plot above?</p>
<p>How do things change if we increase the number of observations or the number of samples? Let’s try while keeping the mean and sd constant. We’ll specify that each sample has 50 observations and we ran 20 samples.</p>
<pre class="r"><code>sim_AQI_data(true_mean=75, true_sd=25, n_obs=50, how_many=20) # trial 2</code></pre>
<p><img src="AQexp2_files/figure-html/simAQIv2-1.png" width="672" /></p>
<p>What do you see now? How have things changed? Where are those sample means (blue lines) located in the first vs. the second plot? Do you see more or less variation in the sample means between trials 1 and 2?</p>
<p>What happens when you change the standard deviation along with the number of observations and number of samples? Try it yourself in the console with:</p>
<p><code>sim_AQI_data(true_means= , true_sd= , n_obs= , how_many= )</code></p>
<p>You’ll have to provide your own values for the true mean and sd for AQI in Pretend City, the number of samples you will run (<code>how_many</code>), and the number of observations (<code>n_obs</code>) of AQI data you’re making in each sample.</p>
<div id="moving-from-samples-to-probabilities" class="section level2">
<h2>Moving from samples to probabilities</h2>
<p>Now we’ve seen how we can calculate means for many different samples, where each sampling regime has different numbers of observations. Let’s take that forward to think about how likely or unlikely any given sample is, when we have some assumption about our world and the data we’ve gathered.</p>
<p>In this case, we are shifting from focusing on the individual data for each sample (gray bars in previous plots) to the distribution of mean values (blue lines in previous plot) across samples. Recall that the mean values are always clustered together more tightly than any individual observation. And in fact, even if our data is really non-normal, we would expect that the distribution of mean values should become more and more like the normal distribution. This expectation comes from the <a href="https://www.simplypsychology.org/central-limit-theorem.html">Central Limit Theorem</a>. Finally, the mean for a set of numbers is a type of <a href="https://en.wikipedia.org/wiki/Statistic">statistic</a>.</p>
<p>We’re going to shift a bit mentally. Instead of our <code>how_many</code> samples, each of which had <code>n_obs</code>, we’re going to think about how likely one sample would be in light of an expected distribution of mean values for AQI.</p>
<p>In the function below, we are going to say that we have a sample of <code>n=10</code> observations and its mean is <code>sample_mean=80</code>. We are also going to provide some information about our universe of possible AQI mean values by specifying the <code>mean=75</code> and <code>sd=25</code>, and that we are gleaning our distribution of mean values from a larger universe of <code>1000 n_samples</code>.</p>
<p>Now in the plot below, the gray bars are the sample means for each of <code>n_samples</code>; this is basically the same as if we plotted the distribution of our blue (mean) lines from the plots above. The vertical dashed line is our observed <code>sample_mean</code>. And the <code>p=...</code> text tells us the probability of observing our sample mean from this universe of possible AQI mean values. The red bars are telling us an added bit of information - namely, the area for our universe of AQI values that is above the 95% probability threshold. That is, 95% of the mean AQI values are smaller than these values in red.</p>
<pre class="r"><code>simu_p(n_samples = 1000, mean=75, sd=25, n=10, distribution=&quot;normal&quot;, sample_mean=80)</code></pre>
<p><img src="AQexp2_files/figure-html/psim-1.png" width="672" /></p>
<div id="your-turn---learning-more-about-probabilities-for-sample-statistics" class="section level3">
<h3>Your turn - learning more about probabilities for sample statistics</h3>
<p>What happens when you observe a larger sample mean? Keep all of the values the same but amp up <code>sample_mean</code> to 90.</p>
<p><code>simu_p(n_samples = 1000, mean=75, sd=25, n=10, distribution="normal", sample_mean=90)</code></p>
<p>What happens when the standard deviation for the “true” mean AQI value is larger?</p>
<p><code>simu_p(n_samples = 1000, mean=75, sd=40, n=10, distribution="normal", sample_mean=80)</code></p>
<p>What happens when the number of observations in each sample is larger? We’ll keep all of the values the same but increase <code>n</code> to 20.</p>
<p><code>simu_p(n_samples = 1000, mean=75, sd=25, n=20, distribution="normal", sample_mean=80)</code></p>
<p>Finally, what happens when the number of observations in each sample is larger and we see a larger sample mean?</p>
<p><code>simu_p(n_samples = 1000, mean=75, sd=25, n=20, distribution="normal", sample_mean=90)</code></p>
</div>
</div>
<div id="statistical-tests-and-probabilities" class="section level2">
<h2>Statistical tests and probabilities</h2>
<p>What we’ve done above is find the probability of observing our sample mean under a variety of different conditions for an underlying distribution of mean AQI values (with a true mean centered at <code>mean</code> in the <code>simu_p</code> function). With this insight, we can extend this approach to formally assess whether our observed data are consistent with our hypothesis.</p>
<p>In statistics (specifically, frequentist statistics), we often denote a null hypothesis with the notation, <span class="math inline">\(H_0\)</span>. For example, in the cases above, our <span class="math inline">\(H_0\)</span> could have been that the true mean AQI in Pretend City was 75. We could specify an alternative view of the world, often denoted <span class="math inline">\(H_a\)</span>. Under our alternative hypothesis, <span class="math inline">\(H_a\)</span>, we would state that the true mean of AQI is not (or is greater than) 75.</p>
<p>In the last trial where we specified <code>simu_p(n_samples = 1000, mean=75, sd=25, n=20, distribution="normal", sample_mean=90)</code>, we saw a very small probability (a.k.a. <span class="math inline">\(p\)</span>-value), often less than 0.005. That is a really tiny probability!</p>
<p>Such a small probability indicate that our sample is quite <strong>unlikely</strong> given the null hypothesis for AQI in Pretend City. That equates to a less than 5 in 1000 chance of seeing our data. These results are inconsistent with <span class="math inline">\(H_0\)</span>, so we reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_a\)</span>, that the true mean AQI is greater than 75. We’ve done a form of statistical inference here!</p>
<p>More broadly, when a <span class="math inline">\(p\)</span>-value is smaller than some cutoff, we describe the results as statistically significant. That means that the data are so inconsistent with the expectations from <span class="math inline">\(H_0\)</span> that we reject the null hypothesis. But what is this cutoff? Historically, many scientists have used a significance level of <span class="math inline">\(\alpha=0.05\)</span>. That is, if our results would occur less than 5% of the time given <span class="math inline">\(H_0\)</span>, then we reject the null. [Sidebar: What would happen if we increased <span class="math inline">\(\alpha=0.1\)</span> or decreased it to <span class="math inline">\(\alpha=0.01\)</span>? Would our statistical inference be more or less conservative (e.g. tendency to not reject <span class="math inline">\(H_0\)</span>)?]</p>
</div>
</div>
<div id="performing-inference-for-a-single-mean" class="section level1">
<h1>Performing inference for a single mean</h1>
<p>Let’s start off with the final sample mean of 90 AQI, a standard deviation of 25, and a sample size of 20 observations. We should recognize that our observed mean may not be the same as the population mean. How can we account for our uncertainty in estimating the true mean AQI from our sample mean? We may want to specify some numerical range of values that seems reasonable.</p>
<p>It turns out that we can calculate what’s known as a <strong>confidence interval (CI)</strong> for our data. A CI presents our statistic and an upper and lower bound, based on some probability value. For instance, a 90% CI means that if we repeated our measurements for 100 samples, 90 of the sample means would be found within our interval. If we increase the probability to 95%, we will end up with a wider confidence interval so that we capture 95 out of the 100 sample means, or 950 out of the 1000 sample means.</p>
<p>We’ll calculate a 95% CI for our mean AQI below. We do so by taking the sample mean and adding (or subtracting) <span class="math inline">\(t_{df} \times SE\)</span>. What is <span class="math inline">\(t_{df}\)</span>? <span class="math inline">\(_{df}\)</span> is the degrees of freedom for our calculation, given by <span class="math inline">\(n-1\)</span> or 19 in this case. <span class="math inline">\(t\)</span> stand’s for Student’s t-distribution, which is a version of the bell-shaped curve normal distribution with wider tails (which accounts for more uncertainty). What is SE? It is short for standard error, and it is <span class="math inline">\(\frac{sd}{\sqrt(n)}\)</span> or <span class="math inline">\(\frac{25}{\sqrt(20)}\)</span>.</p>
<pre class="r"><code>samp_mean &lt;- 90 # our sample mean
samp_sd &lt;- 25 # our sample standard deviation
samp_n &lt;- 20 # our sample number of observations
samp_df &lt;- samp_n - 1 # we are estimating 1 statistic, so we lose 1 degree of freedom from our sample size
samp_se &lt;- samp_sd / sqrt(samp_n) # calculating our standard error
AQI_95_CI_min &lt;- samp_mean - qt(p=0.975,df = samp_df)*samp_se # lower limit
  # why p=0.975? 
  # we take 1 - (1-0.95)/2 to get a symmetric distribution, equivalent to 0.025 and 0.975, 
  # which means that we have 0.95 in between these two values
AQI_95_CI_max &lt;- samp_mean + qt(p=0.975,df = samp_df)*samp_se # upper limit

# Print out values:
paste0(&quot;The 95% CI for mean AQI is [&quot;,signif( AQI_95_CI_min, 3),&quot;,&quot;,signif(AQI_95_CI_max,3),&quot;].&quot;,collapse=&quot;&quot;) # print output; use signif to round to 3 significant figures</code></pre>
<pre><code>## [1] &quot;The 95% CI for mean AQI is [78.3,102].&quot;</code></pre>
<div id="going-further" class="section level2">
<h2>Going further</h2>
<p><a href="https://www.census.gov/programs-surveys/saipe/guidance/confidence-intervals.html">FMI for confidence intervals, please check out this Census Bureau explainer</a> (not required for the class; optional reading in case this is of interest).</p>
</div>
</div>
<div id="comparing-means-across-populations" class="section level1">
<h1>Comparing means across populations</h1>
<p>When we want to compare mean values across two populations, we will often turn to a t-test. In our class, that could look like comparing the mean AQI values measured at one dining hall versus another. Equivalently, it could be mean <span class="math inline">\(O_3\)</span> levels or <span class="math inline">\(CO_2\)</span> or <span class="math inline">\(PM_{2.5}\)</span> across the gym versus the Farm.</p>
<p>In a t-test, we begin with an assumption that the means for the two groups are the same. That is, <span class="math inline">\(H_0: \mu_1 = \mu_2\)</span>. What we have, on the other hand, is a set of sample means, <span class="math inline">\(\bar{x}_1\)</span> and <span class="math inline">\(\bar{x}_2\)</span> (or <span class="math inline">\(\bar{x}_{farm}\)</span> and <span class="math inline">\(\bar{x}_{gym}\)</span>, etc.). Our question is - are the sample means so clearly different that we would reject <span class="math inline">\(H_0\)</span>? Our <span class="math inline">\(H_a\)</span> could be that <span class="math inline">\(\bar{x}_1 \neq \bar{x}_2\)</span> or <span class="math inline">\(\bar{x}_1 &lt; \bar{x}_2\)</span> or <span class="math inline">\(\bar{x}_1 &gt; \bar{x}_2\)</span>.</p>
<p>Let’s begin by using two datasets from the farm and the roadside, collected by Team Fresno.</p>
<pre class="r"><code>farmDF &lt;- googlesheets4::read_sheet(ss=&quot;https://docs.google.com/spreadsheets/d/1Tezs6c3JoCtrdKysVZ02-G7fETLll--v0ZX0Jo9OaB0/edit?usp=sharing&quot;,sheet=&quot;Farm_Clean&quot;) # storing the clean Farm data in farmDF
roadDF &lt;- googlesheets4::read_sheet(ss=&quot;https://docs.google.com/spreadsheets/d/1GIJL9RvfXFiES_bA6rqdpFEX8V24FxX0dfSYmSGTCfw/edit?usp=sharing&quot;,sheet=&quot;Clean_Roadside&quot;) # storing the clean roadside data in roadDF</code></pre>
<p>Great! We’ve pulled in the two clean datasets. Now, in some cases, what you may notice is that the default PL Air column names are not great for working with in <code>R</code>. They have things like spaces, % signs, and other types of issues that make them less than ideal as column names. We’re going to modify those column names below.</p>
<pre class="r"><code>name_vec &lt;- c(&quot;Lat&quot;,&quot;Lng&quot;,&quot;Date&quot;,&quot;tSec&quot;,&quot;Pressure_mBar&quot;,&quot;TempC&quot;,&quot;RelHumPerc&quot;,&quot;Lux&quot;,
              &quot;OzonePPB&quot;,&quot;MeanOzonePPB&quot;,&quot;CO2ppm&quot;,&quot;MeanCO2ppm&quot;,&quot;PM1ugm3&quot;,&quot;MeanPM1&quot;,
              &quot;PM2_5ugm3&quot;,&quot;MeanPM2_5ugm3&quot;,&quot;PM10ugm3&quot;,&quot;MeanPM10ugm3&quot;,&quot;AQI&quot;,
              &quot;HeatIndexC&quot;,&quot;DewPointC&quot;) # creating a vector with cleaner column names
names(farmDF) &lt;- name_vec # changing the column names for farmDF
names(roadDF) &lt;- name_vec # changing the column names for farmDF</code></pre>
<p>Remember, we can always take a quick look at our data by using <code>View( head(farmDF) )</code> or <code>farmDF %&gt;% head() %&gt;% View()</code>.</p>
<p>Let’s say we’re interested in comparing mean AQI values across the two sites. It’s always beneficial to see what the mean values are for our data in the first place! Let’s get a sense of those values by running:</p>
<pre class="r"><code>print(&quot;Summary of AQI values for farm&quot;)</code></pre>
<pre><code>## [1] &quot;Summary of AQI values for farm&quot;</code></pre>
<pre class="r"><code>  # Here, we&#39;re going to use more modern R &quot;syntax&quot; (grammar/commands)
farmDF %&gt;% # feed farm DF forward into the next function
  dplyr::select(AQI) %&gt;% # pulling out the column AQI
    summary() # display the summary of this value </code></pre>
<pre><code>##       AQI       
##  Min.   :61.30  
##  1st Qu.:71.82  
##  Median :76.03  
##  Mean   :75.60  
##  3rd Qu.:80.23  
##  Max.   :90.75</code></pre>
<pre class="r"><code>print(&quot;Summary of AQI values for road&quot;)</code></pre>
<pre><code>## [1] &quot;Summary of AQI values for road&quot;</code></pre>
<pre class="r"><code>summary( roadDF$AQI ) # a different way to call summary using old-school R </code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   65.51   73.92   78.13   78.28   82.33   92.85</code></pre>
<pre class="r"><code>  # we extract the column AQI from roadDF by using the $ operator (?`$` FMI)
  # and that is fed into the command summary()</code></pre>
<p>We see that the road data had a higher AQI on average than the farm data. (What does AQI itself tell us again?) We may now suspect that the mean AQI values are not the same between the Farm and roadside. We can test that with a t-test.</p>
<p>Here, I will show how you can perform a t-test of the AQI values for these two datasets to see if the sample means are likely the same (<span class="math inline">\(H_0\)</span>) or not (<span class="math inline">\(H_a\)</span>).</p>
<pre class="r"><code>my_t_test &lt;- t.test(roadDF$AQI, farmDF$AQI) # run a t-test and store it in my_t_test
my_t_test # print out information about the t-test</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  roadDF$AQI and farmDF$AQI
## t = 7.5515, df = 1245.6, p-value = 8.289e-14
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  1.979843 3.369633
## sample estimates:
## mean of x mean of y 
##  78.27921  75.60447</code></pre>
<div id="interpreting-the-output" class="section level3">
<h3>Interpreting the output</h3>
<p>The test produces a variety of values. We are most interested in the row starting with <code>t =</code>.</p>
<ul>
<li><code>t = 49.15</code> means that the t-statistic for our 2-sample mean comparison was 49.15</li>
<li><code>df = 758.3</code> means that we had over 758 degrees of freedom</li>
<li><code>p-value &lt;</code> <span class="math inline">\(2.2*10^{-16}\)</span> means that our p-value was really tiny, namely 0.00000000000000022.</li>
</ul>
<p>From the test above, we observe that the <span class="math inline">\(p\)</span>-value of <span class="math inline">\(2.2*10^{-16}\)</span> is (waaaay) less than <span class="math inline">\(\alpha=0.05\)</span>, the conventional significance threshold. We would conclude that our means are statistically significantly different and reject the null hypothesis in favor of the alternative hypothesis that the means are not the same.</p>
</div>
<div id="specifying-a-different-h_a" class="section level2">
<h2>Specifying a different <span class="math inline">\(H_a\)</span></h2>
<p>You may now be wondering – but how would I perform a t-test if I had reason to suspect an alternative hypothesis for <span class="math inline">\(H_a\)</span>, namely that the road AQI was higher than the farm AQI? <span class="math inline">\(H_0\)</span> is unchanged (mean AQI is the same across both sites). Below, we’ll run a t-test where <span class="math inline">\(H_a\)</span> is that AQI is greater at the roadside than at the Farm.</p>
<pre class="r"><code>one_sided_t_test &lt;- t.test(roadDF$AQI, farmDF$AQI, alternative = &quot;greater&quot;) # specify a different H_a: road AQI &gt; farm AQI
one_sided_t_test # display test results</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  roadDF$AQI and farmDF$AQI
## t = 7.5515, df = 1245.6, p-value = 4.145e-14
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  2.091697      Inf
## sample estimates:
## mean of x mean of y 
##  78.27921  75.60447</code></pre>
<p>Note in the <code>t.test</code> command above, that <code>alternative = "greater"</code> is how we are specifying an <span class="math inline">\(H_a\)</span> that the first sample (<code>roadDF$AQI</code>) is greater than the second sample (<code>farmDF$AQI</code>). Alternatively, you could have the same <span class="math inline">\(H_a\)</span> but specify that <code>farmDF$AQI</code> is less than <code>roadDF$AQI</code>.</p>
<pre class="r"><code>one_sided_t_test &lt;- t.test(farmDF$AQI, roadDF$AQI, alternative=&quot;less&quot;) # farm AQI &lt; road AQI
one_sided_t_test # display test</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  farmDF$AQI and roadDF$AQI
## t = -7.5515, df = 1245.6, p-value = 4.145e-14
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##       -Inf -2.091697
## sample estimates:
## mean of x mean of y 
##  75.60447  78.27921</code></pre>
<p>In both of these one-sided tests, we would reject <span class="math inline">\(H_0\)</span> – the means are statistically significantly different in favor of the alternative hypothesis that roadside AQI is higher than the Farm AQI.</p>
</div>
<div id="going-further-1" class="section level2">
<h2>Going further</h2>
<p>In case you have any curiosity about learning more about t-tests, here is some material (not required for this course). <a href="https://openintro-ims.netlify.app/inference-two-means.html#math2samp">FMI about t-tests here</a> for the curious - see section 20.3 in particular. This textbook is co-authored by Pomona’s very own <a href="https://hardin47.netlify.app/courses/">Prof. Jo Hardin</a>.</p>
</div>
</div>
<div id="comparing-more-than-two-means" class="section level1">
<h1>Comparing more than two means</h1>
<p>Let’s say that your PL Air data come from three or more distinct populations/sites. How would you compare them? You can use a method called Analysis of Variance (ANOVA). ANOVA lets you compare three or more sets of data. Despite “variances” in the name, under ANOVA we are comparing the spread of values across datasets (where each dataset is a population or site) to see if the means are significantly different.</p>
<p>Here, we’ll use three datasets from Team Bird’s Eye. If you ever need to clean up your iPhone data, you can follow the steps from <a href="https://ea30pom.github.io/Fall2021/AQexp1.html">last week here</a> in the <strong>iOS Data</strong> section.</p>
<pre class="r"><code>df3 &lt;- read_sheet(ss=&quot;https://docs.google.com/spreadsheets/d/1P1orGfuKIG2E4IuCoE1HKyPS09d6x4pu_OlV3IWGPFY/edit?usp=sharing&quot;,sheet=&quot;Clean&quot;) # read in the Clean datasheet from this Googlesheet and store it in df3
df2 &lt;- read_sheet(ss=&quot;https://docs.google.com/spreadsheets/d/1V79fkoO-CoHtiqtLKYnVc1MTwuyonhRoWNJfaOQChKU/edit?usp=sharing&quot;,sheet=&quot;Clean&quot;) # read in another Googlesheet&#39;s Clean sheet and store in df2
df1 &lt;- read_sheet(ss=&quot;https://docs.google.com/spreadsheets/d/1iznRXt4vFcFlkLCRNHHAEXG19CAPMc6r14K9oLoiDkY/edit?usp=sharing&quot;,sheet=&quot;Clean&quot;) # same as above, but store another Googlesheet&#39;s Clean sheet as df1</code></pre>
<p>Instead of repeating the type of procedure above where we directly compared different data sheets, here we will need to join up our data and find some way to separate them into groups. I will do that using the <code>Date</code> time stamps.</p>
<pre class="r"><code>birdDF &lt;- bind_rows(df1,df2,df3) # combine the 3 data sets row by row
birdDF &lt;- birdDF %&gt;% na.omit() # remove rows that are all missing values
names(birdDF) &lt;- name_vec # we will rename the columns using name_vec from before</code></pre>
<p>One really cool thing we can do is see the total time elapsed in our data by running <code>tail(birdDF$Date, 1) - head(birdDF$Date, 1)</code>–we’d see that these data span 48.34 minutes, or about 48 minutes and 20 seconds.</p>
<p>Originally, the data came from three locations at varying distances to the Pomona gym. How can we now separate the data into different buckets to compare means across levels of distance? We can use those timestamps to our advantage. We’re going to define new categories based on 20 minute increments in our data</p>
<pre class="r"><code>dist_labels &lt;- c(96.6, 207, 300) # the distance classes to the gym associated with the time slices
birdDF &lt;- birdDF %&gt;%
  mutate(Distances = cut(birdDF$Date,breaks=&quot;20 min&quot;,labels=dist_labels)) # slice the date times into categories based on 20 minute intervals and label each slice based on the distance labels, store this variable in a new column called Distances using the command, mutate 

# Here, we can see the counts of each categorical break by time
# How many observations does each grouped set of data have?
birdDF %&gt;% # feed birdDF forward
  dplyr::select(Distances) %&gt;% # pull out the column Distances; equivalent to birdDF$Distances
  table() # show us the counts by each unique value in Distances</code></pre>
<pre><code>## .
## 96.6  207  300 
##  827  733  560</code></pre>
<pre class="r"><code># We can also see the mean values for AQI for the different distances this way
birdDF %&gt;% # feed birdDF forward to the next function
  group_by(Distances) %&gt;% # bucket the data into different Distance bins
  summarize(minAQI = min(AQI), medianAQI = median(AQI), meanAQI = mean(AQI), maxAQI = max(AQI)) # produce a data summary based on the AQI values observed in each distance class</code></pre>
<pre><code>## # A tibble: 3 x 5
##   Distances minAQI medianAQI meanAQI maxAQI
##   &lt;fct&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1 96.6        67.6      82.3    82.4   95.0
## 2 207         67.6      80.2    80.4   95.0
## 3 300         65.5      78.1    78.4   88.6</code></pre>
<p>Now, we will run the ANOVA test on our data. We will compare the AQI values for the three distance classes of 96.6, 207, and 300 feet from the gym. We do so using these commands:</p>
<pre class="r"><code>aov_test &lt;- aov( lm(AQI~Distances, data=birdDF )) # perform an ANOVA test of AQI as a function of Distances, which are both found in the object birdDF and store it in aov_test
summary( aov_test ) # show our output for aov_test using the command summary( ); note that you don&#39;t need to use summary( ) for the t-test output though </code></pre>
<pre><code>##               Df Sum Sq Mean Sq F value Pr(&gt;F)    
## Distances      2   5420  2709.9    81.5 &lt;2e-16 ***
## Residuals   2117  70387    33.2                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div id="interpreting-the-anova-test" class="section level3">
<h3>Interpreting the ANOVA test</h3>
<p>The ANOVA test produces a table with different outputs. We are most interested in the row corresponding to our variable of interest, <code>Distances</code>.</p>
<p>In that row:</p>
<ul>
<li><code>Df</code> is the number of parameters we were estimating, minus 1 (3 means)</li>
<li><code>Sum Sq</code> is total sum of squares of all values from the overall mean for all the data (this is not important for our purposes in this class)</li>
<li><code>Mean Sq</code> is the mean value for the sum-of-squares (again, not important for us)</li>
<li><code>F value</code> is a different test statistic, the F-statistic (not important for us at present)</li>
<li><code>Pr(&gt;F)</code> shows us the p-value associated with the F-statistic (important for us). Here, the p-value is again very small–almost zero.</li>
</ul>
<p>Based on the small p-value, we would reject the null hypothesis, <span class="math inline">\(H_0\)</span>, that the mean AQI across all of the sites was the same. We observe significant differences in mean AQI across the three locations at different distances to the gym.</p>
<p>We may be curious about which distances ultimately have different AQI values. Here is one way to do this analysis using a method known as Tukey’s Honestly Significant Difference (HSD) test, named after the statistician Prof. John Tukey. Among many other contributions, Prof. Tukey also helped develop the box plot, one very helpful way of visualizing distributions of data. We’ll learn more about box plots later on in this class.</p>
<p>The Tukey HSD outputs a table of p-values as well as the 95% confidence intervals for the lower and upper bound of the differences between the means of two groups. If <span class="math inline">\(p_{adj} &lt; \alpha\)</span> where <span class="math inline">\(\alpha\)</span> typically is 0.05, then we conclude that there is a significant difference between the means of those two groups. So below, we would conclude that AQI is lower at 207 feet from the gym than at 96.6 feet, and that it is lower at 300 feet than 207 feet, and that it is lower at 300 feet than 96.6 feet away from the gym.</p>
<pre class="r"><code>TukeyHSD( aov_test,&quot;Distances&quot;) # tell the command the name of your ANOVA model (aov_test) and the column used to categorize the data (Distances)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = lm(AQI ~ Distances, data = birdDF))
## 
## $Distances
##               diff       lwr       upr p adj
## 207-96.6 -2.018234 -2.704280 -1.332189     0
## 300-96.6 -3.999786 -4.739880 -3.259692     0
## 300-207  -1.981552 -2.740564 -1.222540     0</code></pre>
<p>In the TukeyHSD output, the values in the table correspond to:</p>
<ul>
<li><code>diff</code>: the difference between one group’s mean and another</li>
<li><code>lwr</code>: the lower limit for the confidence interval of the difference between means</li>
<li><code>upr</code>: the upper limit for the CI of the difference between means</li>
<li><code>p adj</code>: the p-value adjusted for <a href="http://www.biostathandbook.com/multiplecomparisons.html">multiple comparisons</a>; this takes into account the fact that statistical tests themselves are probabilistic, and the more tests we run, the more we’d expect to get a falsely significant result just by chance.</li>
</ul>
</div>
<div id="going-further-2" class="section level2">
<h2>Going further</h2>
<p>If you would like to learn more about ANOVA tests and Tukey HSD, please <a href="https://mgimond.github.io/Stats-in-R/ANOVA.html#4_identifying_which_levels_are_different">refer to these materials</a> (not necessary for this course; provided in case it is of interest).</p>
</div>
</div>
<div id="linear-regression" class="section level1">
<h1>Linear regression</h1>
<p>We may be thinking – but wait, couldn’t we directly model the relationship between distance and AQI? Indeed we can, and we can use linear regression to do so. Linear regression is used to model the relationship between a dependent (a.k.a. response) variable, which we will denote <span class="math inline">\(Y\)</span>, and one or more independent (a.k.a. explanatory) variables denoted as <span class="math inline">\(X_1, X_2, X_3, \dots, X_k\)</span> (representing a total of <span class="math inline">\(k\)</span> arbitrary independent variables). In the case of the Bird’s Eye PL Air data, the response variable <span class="math inline">\(Y\)</span> is <code>AQI</code> and the independent variable <span class="math inline">\(X\)</span> is <code>Distances</code>.</p>
<div id="what-does-linear-regression-do" class="section level2">
<h2>What does linear regression do?</h2>
<p>Using a linear model, we are going to fit a line that describes the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Recall that the equation for a straight line is:</p>
<p><span class="math inline">\(Y = b + mx\)</span></p>
<p>In linear regression, we are estimating:</p>
<p><span class="math inline">\(Y = \beta_0 + \beta_1 X_1\)</span></p>
<p>Equivalently, in the case of our butterfly data, we are estimating:</p>
<p><span class="math inline">\(\text{AQI} = \beta_0 + \beta_1 \text{Distances}\)</span></p>
<p>Note that you can interpret <span class="math inline">\(\beta_0\)</span> to be the same as <span class="math inline">\(b\)</span> from the equation for a straight-line. That is, <span class="math inline">\(\beta_0\)</span> is the y-intercept: it tells us what the value of <span class="math inline">\(Y\)</span> would be when <span class="math inline">\(X_i = 0\)</span> for all of the independent variable(s). In this case, we only have 1 independent variable, so <span class="math inline">\(\beta_0\)</span> tells us what we would expect AQI to be when distance (to the gym) is equal to 0. <span class="math inline">\(\beta_1\)</span> is the same as <span class="math inline">\(m\)</span>: it tells us the slope of the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1\)</span>.</p>
</div>
<div id="estimating-the-linear-regression-model-for-the-example-data" class="section level2">
<h2>Estimating the linear regression model for the example data</h2>
<p>Below, we will use the <code>lm</code> command (short for linear model) in <code>R</code> to estimate the coefficients, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> for the data. <code>lm</code> performs a specific type of linear regression, which is known as “ordinary least squares” (OLS for short) regression.</p>
<pre class="r"><code>### First, we need to convert Distances from a factor (categorical)
### data to numeric data
birdDF &lt;- birdDF %&gt;% # feed birdDF forward to next function/command
  mutate(Distances = as.numeric(Distances)) # make Distances a number instead of a factor using mutate

### Running the lm command
AQImodel &lt;- lm(AQI ~ Distances, data=birdDF)

### Showing the coefficient estimates
summary(AQImodel)</code></pre>
<pre><code>## 
## Call:
## lm(formula = AQI ~ Distances, data = birdDF)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.8175  -4.4043  -0.1983   4.1095  14.5227 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  84.4324     0.3192  264.48   &lt;2e-16 ***
## Distances    -2.0011     0.1567  -12.77   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.765 on 2118 degrees of freedom
## Multiple R-squared:  0.07149,    Adjusted R-squared:  0.07105 
## F-statistic: 163.1 on 1 and 2118 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>What have we done here?</p>
<p>First, we have run a linear regression model relating AQI to Distances using the syntax <code>AQI ~ Distances</code> where the <code>~</code> means “AQI is distributed according to Distances [to the gym]”.</p>
<p>We have stored the output of the linear regression in the object <code>AQImodel</code>.</p>
<p>Finally, we have used the <code>summary</code> command on the <code>AQImodel</code> object to display information about the estimated values in the model, which include our coefficients <span class="math inline">\(\beta_0\)</span> (<code>(Intercept)</code>) and <span class="math inline">\(\beta_1\)</span> (<code>Distances</code>).</p>
</div>
<div id="interpreting-these-values" class="section level2">
<h2>Interpreting these values</h2>
<p>What do the values in the <code>summary</code> output reveal about the relationship between AQI and distance? We’ll focus on the table in the <code>summary</code> output that begins with <code>Coefficients:</code>.</p>
<p>The coefficients output is copied again here for convenience.</p>
<pre><code>Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  84.4324     0.3192  264.48   &lt;2e-16 ***
Distances    -2.0011     0.1567  -12.77   &lt;2e-16 ***</code></pre>
<p>The <code>Coefficients:</code> table has two rows. Each row corresponds to our two variables: the intercept (<span class="math inline">\(\beta_0\)</span>) and Distances (<span class="math inline">\(\beta_1\)</span>).</p>
<p>The <code>Estimate</code> column tells us the estimated values for the <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> coefficients.</p>
<p>The <code>Std. Error</code> column tells us the standard error of each coefficient, which is a measure of the uncertainty in the estimated value of the coefficient. Basically, when the relationship between <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y\)</span> has a lot of spread, the standard errors will grow larger. On the other hand, when there is a very close relationship between <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y\)</span> (less spread in the data), the standard errors become smaller.</p>
<p>The <code>t-value</code> gives us the t-statistic for each coefficient, which is calculated as <code>Estimate / Std. Error</code>. Effectively, the <code>t value</code> is a measure of how far (in terms of standard deviations) each coefficient is from 0. That is, the <code>t value</code> is a statistic testing whether or not the true value of the coefficient, given our data and model, is likely to be 0 or not.</p>
<p>Finally, <code>Pr(&gt;|t|)</code> shows us the probability value (or p-value) associated with each coefficient in the table. The p-values shown in the <code>Pr(&gt;|t|)</code> column tell us how probable it is that we would observe any value <span class="math inline">\(\geq\)</span> the coefficient estimate. Given <span class="math inline">\(\alpha=0.05\)</span>, when <span class="math inline">\(p &lt; \alpha\)</span>, we can reject the null hypothesis, <span class="math inline">\(H_0\)</span>. <span class="math inline">\(H_0\)</span> is that there is no relationship, meaning that <span class="math inline">\(\beta_i\)</span> for <span class="math inline">\(X_i\)</span> = 0, between <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y\)</span>. Let’s see how this plays out with this example below.</p>
<p>The value for <code>(Intercept)</code> (a.k.a. <span class="math inline">\(\beta_0\)</span>) tells us that when <code>Distances=0</code>, we would predict that AQI is 84.4 right next to the gym. In and of itself, this intercept is interesting but not super meaningful.</p>
<p>The value for <code>Distances</code> (a.k.a. <span class="math inline">\(\beta_1\)</span>), which is -2.0 (rounding to 1 or 2 decimal places is usually preferable to presenting a number with many floating points/decimal places), is more interesting. It tells us that as distance <strong>increases by 1 foot</strong> (<code>Distances + 1</code>), AQI decreases by 2 points. Alternatively, if we move one foot closer to the gym, AQI increases by 2 points. Given the very small <span class="math inline">\(p\)</span>-value associated with <code>Distances</code> (<span class="math inline">\(\beta_1\)</span>), we conclude that we can reject the null hypothesis that there is no relationship. These data indicate that there is a significant, negative relationship between AQI and distance, or that AQI decreases significantly with distance to the gym.</p>
<div id="hat-tips" class="section level3">
<h3>Hat tips</h3>
<p>This week’s statistics segment was heavily inspired by Professors Hardin, <a href="https://github.com/mgimond/">M. Gimond</a> at Colby College, and <a href="https://data-se.netlify.app/about/">S. Sauer</a> at Ansbasch University.</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
